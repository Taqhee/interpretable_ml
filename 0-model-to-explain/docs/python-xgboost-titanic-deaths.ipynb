{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "In this document I will create a XGBoost model to predict which passengers will die in the sinking of the Titanic. \n",
    "\n",
    "This model will be used later to compare several interpretability tools.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this reproducible\n",
    "random.seed(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "training_set = pd.read_csv(\"../../data/titanic/train.csv\")\n",
    "test_set = pd.read_csv(\"../../data/titanic/test.csv\")\n",
    "labels = pd.read_csv(\"../../data/titanic/titanic-labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to test set\n",
    "labels = labels.loc[:, [\"name\", \"age\", \"survived\"]]\n",
    "test_set_with_labels = test_set.merge(labels, how = 'left', left_on = [\"Name\", \"Age\"], right_on = [\"name\", \"age\"])\n",
    "test_set_with_labels.drop(columns = [\"name\", \"age\"], inplace = True)\n",
    "test_set = test_set_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and transform data\n",
    "\n",
    "Remove non-important features (or too complex ones) and create categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.drop(columns = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace = True)\n",
    "test_set.drop(columns = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.rename(columns={'survived': 'Survived'}, inplace=True)\n",
    "test_set = test_set[test_set.Survived.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josearcos/miniconda3/envs/titanic/lib/python3.5/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "test_set.at[:, \"Survived\"] = test_set.Survived.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.get_dummies(training_set, columns = [\"Pclass\", \"Embarked\"], drop_first = False) \n",
    "test_set = pd.get_dummies(test_set, columns = [\"Pclass\", \"Embarked\"], drop_first = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.Sex = training_set.Sex.apply(lambda x: int(x == \"male\"))\n",
    "test_set.Sex = test_set.Sex.apply(lambda x: int(x == \"male\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to convert our data sets to xgboost DMatrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(data = training_set.drop(columns=\"Survived\"),\n",
    "                        label = training_set.loc[:, \"Survived\"])\n",
    "\n",
    "xgb_test = xgb.DMatrix(data = test_set.drop(columns=\"Survived\"),\n",
    "                       label = test_set.loc[:, \"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's chose the hyperparameters using random search and cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "eta = np.random.uniform(low = 0.01, high = 0.3, size = n_trials)\n",
    "max_depth = np.random.randint(low = 3, high = 11, size = n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = list()\n",
    "for i in range(n_trials):\n",
    "    params = {\n",
    "        \"eta\": eta[i],\n",
    "        \"max_depth\": max_depth[i],\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"silent\": 1,\n",
    "        \"eval_metric\": \"error\"\n",
    "    }\n",
    "    result = xgb.cv(params = params,\n",
    "                    dtrain = xgb_train, \n",
    "                    num_boost_round = 200, \n",
    "                    nfold = 5, \n",
    "                    stratified = True,\n",
    "                    early_stopping_rounds = 5)\n",
    "    results_cv.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [res[\"test-error-mean\"].min() for res in results_cv]\n",
    "rounds = [res.shape[0] for res in results_cv]\n",
    "best_trial = np.argmin(errors)\n",
    "best_eta = eta[best_trial]\n",
    "best_max_depth = max_depth[best_trial]\n",
    "best_nrounds = rounds[best_trial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trials: 1000\n",
      "eta: 0.276, max_depth: 6, nrounds: 19, error = 0.163\n"
     ]
    }
   ],
   "source": [
    "print(\"# trials: {}\".format(n_trials))\n",
    "print(\"eta: {0:.3}, max_depth: {1}, nrounds: {2}, error = {3:.3}\".format(best_eta, best_max_depth, best_nrounds, min(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's train the model with the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth = best_max_depth, learning_rate = best_eta,\n",
    "                         n_estimators = best_nrounds, silent = False,\n",
    "                         objective = 'binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.27553718933881405,\n",
       "       max_delta_step=0, max_depth=6, min_child_weight=1, missing=None,\n",
       "       n_estimators=19, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=False,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X = training_set.drop(columns = \"Survived\"), \n",
    "          y = training_set.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test set and estimate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josearcos/miniconda3/envs/titanic/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_set.drop(columns = \"Survived\"))\n",
    "test_predictions = [(x > 0.5).astype(int) for x in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(test_predictions == test_set.Survived) / len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy = 0.78\n"
     ]
    }
   ],
   "source": [
    "print(\"validation accuracy = {0:.3}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain almost the same result than the R version. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and data set to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model_and_data_python.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things_to_save = [model, training_set, test_set]\n",
    "joblib.dump(value = things_to_save, filename = \"../model_and_data_python.sav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
